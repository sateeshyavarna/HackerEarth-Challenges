{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"PredictDamage.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gFN1CcPdTCx4"},"source":["ALL Imports"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1822,"status":"ok","timestamp":1542620065072,"user":{"displayName":"Sateesh Yavarn","photoUrl":"","userId":"17604088172453883171"},"user_tz":-330},"id":"FxDdROk_SyXc","outputId":"3bc2b10c-28f8-46dd-cba9-dd5a651a2b3e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Imports\n","\n","import  pandas as pd\n","import os\n","import numpy as np\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn import preprocessing\n","\n","print(\"Imported All Imports\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Imported All Imports\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":23449,"status":"ok","timestamp":1530972314510,"user":{"displayName":"Sateesh Yavarn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115031507397726858001"},"user_tz":-330},"id":"qmmKV0N6TIQS","outputId":"e461e525-e103-46f9-911b-bed39c3c1a4e","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["#os.chdir(\"godrive/app/predictDamage\")\n","\n","#!ls -l /home/\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":3332,"status":"ok","timestamp":1530972327918,"user":{"displayName":"Sateesh Yavarn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115031507397726858001"},"user_tz":-330},"id":"rLls4h4UaAlu","outputId":"27715293-e90a-4c0f-c53f-8eef5768ddf5","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["#  !ls -l drive/app/predictDamage\n","# !cd drive/app/predictDamage\n","# !pwd\n","\n","import os\n","os.chdir(\"drive/app/predictDamage\")\n","os.listdir()\n","\n","!ls -l\n","# !cd drive/app"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 324735\r\n","-rw-r--r-- 1 root root  67531978 Jul  6 16:37 Building_Ownership_Use.csv\r\n","-rw-r--r-- 1 root root 196802973 Jul  6 16:39 Building_Structure.csv\r\n","-rw-r--r-- 1 root root     23657 Jul  7 14:04 PredictDamage.ipynb\r\n","-rw-r--r-- 1 root root   8902245 Jul  6 16:39 sample_submission.csv\r\n","-rw-r--r-- 1 root root  21684298 Jul  6 16:36 test.csv\r\n","-rw-r--r-- 1 root root  37581420 Jul  6 16:36 train.csv\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f50W0bLJeDzL","colab":{}},"source":["import  pandas as pd\n","train = pd.read_csv(\"train.csv\")\n","ownerShip = pd.read_csv(\"Building_Ownership_Use.csv\")\n","structure = pd.read_csv(\"Building_Structure.csv\")\n","train_ownership = pd.merge(train, ownerShip, on='building_id', how='inner')\n","train_ownership_str = pd.merge(train_ownership, structure, on='building_id', how='inner')\n","\n","# train_ownership_str = pd.read_pickle(\"train_ownership_str.pkl\")\n","# train_ownership_str.head(2)\n","# train_ownership_str.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":3653,"status":"ok","timestamp":1530973067369,"user":{"displayName":"Sateesh Yavarn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115031507397726858001"},"user_tz":-330},"id":"B8esTuDvjok8","outputId":"85702f13-2366-460e-ebec-03163825407b","colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["X = train_ownership_str[train_ownership_str.columns.difference(['bulding_id','damage_grade'])]\n","Y = pd.DataFrame(train_ownership_str.loc[:, 'damage_grade'])\n","colsToExclude = ('building_id')\n","def missing_values_table(df):\n","    mis_val = df.isnull().sum()\n","    mis_val_percent = 100 * df.isnull().sum() / len(df)\n","    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n","    mis_val_table_ren_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n","    mis_val_table_ren_columns = mis_val_table_ren_columns[mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(2)\n","    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n","        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n","          \" columns that have missing values.\")\n","    return mis_val_table_ren_columns\n","\n","missing_values_table(X)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Your selected dataframe has 57 columns.\n","There are 2 columns that have missing values.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Missing Values</th>\n","      <th>% of Total Values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>has_repair_started</th>\n","      <td>33417</td>\n","      <td>5.29</td>\n","    </tr>\n","    <tr>\n","      <th>count_families</th>\n","      <td>1</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    Missing Values  % of Total Values\n","has_repair_started           33417               5.29\n","count_families                   1               0.00"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":8221,"status":"ok","timestamp":1530973080969,"user":{"displayName":"Sateesh Yavarn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115031507397726858001"},"user_tz":-330},"id":"i3WZg93cjwIT","outputId":"642641bb-7505-4e8b-d428-99db41dbea20","colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["def imputeMissingValues(df,categoryMethod,numericalMethod,categoryPackage,numericalPacakge,colsToExclude):\n","    catModule = __import__(categoryPackage)\n","    catFunc = getattr(catModule, categoryMethod)\n","    numModule = __import__(numericalPacakge)\n","    numFunc = getattr(numModule, numericalMethod)\n","    whereModule = __import__(\"numpy\")\n","    whereFunc = getattr(whereModule, \"where\")\n","    for col in df:\n","      if df[col].dtype == 'object' and col not in colsToExclude:\n","          df[col] = whereFunc(df[col].isnull(),catFunc(df[col]),df[col])\n","      elif df[col].dtype in ('float64', 'int64', 'int32' ,'float32' ) and col not in colsToExclude:\n","          df[col] = whereFunc(df[col].isnull(),numFunc(df[col]),df[col])\n","\n","imputeMissingValues(X,\"mode\",\"nanmean\",\"statistics\",\"numpy\",colsToExclude)\n","missing_values_table(X)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  # Remove the CWD from sys.path while we load stuff.\n"],"name":"stderr"},{"output_type":"stream","text":["Your selected dataframe has 57 columns.\n","There are 0 columns that have missing values.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Missing Values</th>\n","      <th>% of Total Values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [Missing Values, % of Total Values]\n","Index: []"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":5228,"status":"ok","timestamp":1530973094336,"user":{"displayName":"Sateesh Yavarn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115031507397726858001"},"user_tz":-330},"id":"vawq3Z1zlFPG","outputId":"796db5da-6ba2-43ab-f621-f550655e7cee","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["def labelEncodingOfVariables(df, minNoOfUniqueClass, colsToExclude):\n","    from sklearn.preprocessing import LabelEncoder\n","    le = LabelEncoder()\n","    noOfColsLabeld = 0\n","    colsLabelled = list()\n","    for col in df:\n","        if df[col].dtype == 'object' and col not in colsToExclude:\n","            if len(list(df[col].unique())) <= minNoOfUniqueClass:\n","                le.fit(df[col])\n","                colsLabelled.append(col)\n","                df[col] = le.transform(df[col])\n","                noOfColsLabeld += 1\n","                print(\"Label Encoding done for %s\" % col)\n","    print(\"Total Number of coloumns Labelled are %d\" % noOfColsLabeld)\n","    return colsLabelled\n","\n","\n","colsLabelled_X = labelEncodingOfVariables(X, 3, colsToExclude)\n","colsLabelled_Y = labelEncodingOfVariables(Y, 5, colsToExclude)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Label Encoding done for land_surface_condition\n","Label Encoding done for roof_type\n","Total Number of coloumns Labelled are 2\n","Label Encoding done for damage_grade\n","Total Number of coloumns Labelled are 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rtADWd1PlTZD","colab":{}},"source":["def oneHotEncodingOfVariable(data,colsToExclude):\n","    import pandas as pd\n","    for col in data:\n","      if data[col].dtype == 'object' and col not in colsToExclude:\n","          data = pd.get_dummies(data, columns= [col], prefix=[col], prefix_sep='_')\n","    return data\n","X = oneHotEncodingOfVariable(X,('building_id'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yBdvM8o0lyIR","colab":{}},"source":["def removeConstantVariables(data,colsToExclude):\n","    colsRemoved = list()\n","    for col in data:\n","      if col not in colsToExclude and data[col].std() == 0:\n","        colsRemoved.append(col)\n","        data.drop(col, axis=1, inplace = True)\n","    return colsRemoved\n","\n","colsRemoved = removeConstantVariables(X,colsToExclude)\n","\n","\n","def removeDuplicateVariables(data):\n","    import numpy as np\n","    cols = data.columns\n","    colsScanned = list()\n","    colsToRemove = list()\n","    for i in range(len(cols) - 1):\n","        values = data[cols[i]].values\n","        dupColoumns = list()\n","        for j in range(i + 1, len(cols)):\n","            if np.array_equal(values, data[cols[j]].values):\n","                colsToRemove.append(cols[j])\n","                if cols[j] not in colsScanned:\n","                    dupColoumns.append(cols[j])\n","                    colsScanned.append(cols[j])\n","    return colsToRemove\n","\n","\n","colsToRemove = removeDuplicateVariables(X)\n","X.drop(colsToRemove,axis=1,inplace=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":12726,"status":"ok","timestamp":1530973131606,"user":{"displayName":"Sateesh Yavarn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115031507397726858001"},"user_tz":-330},"id":"PUjd3p25mzmk","outputId":"d67ba51a-e371-4689-886c-b03d2dcda8a2","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["def correlation(dataset, threshold):\n","    col_corr = {} # Set of all the names of deleted columns\n","    corr_matrix = dataset.corr()\n","    for i in range(len(corr_matrix.columns)):\n","        for j in range(i):\n","            if corr_matrix.iloc[i, j] > threshold:\n","                colname = corr_matrix.columns[i] # getting the name of column\n","                col_corr[colname] = corr_matrix.iloc[i, j]\n","                if colname in dataset.columns:\n","                   del dataset[colname] # deleting the column from the dataset\n","    for key, val in col_corr.items():\n","        print(key, \"=>\", val)\n","    # print(dataset)\n","\n","correlation(X,0.70)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["has_geotechnical_risk_landslide => 0.7273914945038104\n","has_secondary_use_agriculture => 0.7348965503435323\n","height_ft_post_eq => 0.9410595781983775\n","height_ft_pre_eq => 0.7735538486810057\n","vdcmun_id => 0.9996936523100862\n","ward_id_x => 0.9999999988425701\n","condition_post_eq_Damaged-Repaired and used => 0.7027756925535288\n","condition_post_eq_Damaged-Rubble clear => 0.7405041351024928\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-U5xVCIVm-Mr","colab":{}},"source":["X.drop('building_id',axis=1,inplace=True)\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.33)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZEVTF08MnAPx","colab":{}},"source":["def evaluateClassificationModels(X_train,X_test,Y_train,Y_test):\n","    #Imports\n","    from sklearn import linear_model\n","    from sklearn.metrics import accuracy_score\n","    from sklearn.metrics import confusion_matrix\n","    import pandas as pd\n","    from sklearn import ensemble\n","    from sklearn import neighbors\n","    from sklearn.neural_network import MLPClassifier\n","    from sklearn import tree\n","    from sklearn.neighbors import KNeighborsClassifier\n","    from sklearn.svm import SVC\n","    from sklearn.naive_bayes import GaussianNB\n","    from sklearn.ensemble import AdaBoostClassifier\n","    from sklearn.model_selection import GridSearchCV\n","    from sklearn.metrics import precision_score,recall_score\n","    from sklearn.linear_model import SGDClassifier\n","    from sklearn.linear_model import PassiveAggressiveClassifier\n","    #Models\n","    classificationModels = list()\n","    keysOfParam = set()\n","#     params_lr = [\n","#     {'penalty': ['l1'],'C': [1, 10, 100, 1000], 'solver' : ['liblinear','saga']},\n","#     {'penalty': ['l2'],'C': [1, 10, 100, 1000], 'solver' : ['newton-cg','sag','lbfgs']}\n","#     ]\n","#     lr = linear_model.LogisticRegression()\n","#     classificationModels.append(('Logistic Regression',lr,params_lr))\n","    params_rf = [\n","    {'n_estimators' : [10,20,30,50,100],'criterion' : ['gini'],'max_features':['sqrt','log2']},\n","    {'n_estimators' : [10,20,30,50,100],'criterion' : ['entropy'],'max_features':['sqrt','log2']}\n","     ]\n","    rf = ensemble.RandomForestClassifier()\n","    classificationModels.append(('RandomForest',rf,params_rf))\n","#     params_kn = [\n","#        {'n_neighbors' : [1,5,10,15,20,25,30],'weights' : ['uniform'],'algorithm' : ['auto','ball_tree','kd_tree','brute'],'leaf_size' : [5,10,15,20,25,30],'p' : [1,2]},\n","#        {'n_neighbors' : [1,5,10,15,20,25,30],'weights' : ['distance'],'algorithm' : ['auto','ball_tree','kd_tree','brute'],'leaf_size' : [5,10,15,20,25,30],'p' : [1,2]}\n","#      ]\n","#     kn = neighbors.KNeighborsClassifier()\n","#     classificationModels.append(('KNeighbors',kn,params_kn))\n","#     params_mlp = [\n","#        {'hidden_layer_sizes' : [50,75,100,125,150,175,200],'activation' : ['identity','logistic','tanh','relu'],'solver' : ['lbfgs','sgd','adam'],'learning_rate' : ['constant','invscaling','adaptive']},\n","#        {'hidden_layer_sizes' : [50,75,100,125,150,175,200],'activation' : ['identity','logistic','tanh','relu'],'solver' : ['sgd'],'learning_rate' : ['constant','invscaling','adaptive']}\n","#      ]\n","#     mlp = MLPClassifier()\n","#     classificationModels.append(('MLPClassifier',mlp,params_mlp))\n","\n","#     params_tr = [\n","#        {'criterion' : ['gini'],'splitter' : ['best','random'],'max_features' : ['auto','log2']},\n","#        {'criterion' : ['entropy'] ,'splitter' : ['best','random'],'max_features' : ['auto','log2']}\n","#      ]\n","#     tr = tree.DecisionTreeClassifier()\n","#     classificationModels.append(('DecisionTree',tr,params_tr))\n","\n","#     params_boost = [\n","#        {'n_estimators' : [10,20,30,50,100],'random_state' : [5,7,8,9,11]},\n","#        {'n_estimators' : [60,70,80,90,110],'random_state' : [12,13,14]}\n","#      ]\n","#     ada = AdaBoostClassifier()\n","#     classificationModels.append(('AdaBoostClassifier',ada,params_boost))\n","#     params_SGD = [\n","#          {'loss' : ['hinge','log','modified_huber','squared_hinge','perceptron'], 'penalty' : ['l1']},\n","#          {'loss' : ['hinge','log','modified_huber','squared_hinge','perceptron'], 'penalty' : ['l2']},\n","#          {'loss' : ['hinge','log','modified_huber','squared_hinge','perceptron'], 'penalty' : ['elasticnet']}\n","#        ]\n","#     SGD = SGDClassifier()\n","#     classificationModels.append(('Stochastic Gradient Classifier',SGD,params_SGD))\n","#     params_PA = [\n","#          {'C': [1, 10, 100, 1000],'random_state' : [5,7,8,9,11]}\n","#        ]\n","#     PA = PassiveAggressiveClassifier()\n","#     classificationModels.append(('Passive Aggressive Classifier',PA,params_PA))\n","    #     params_SVC = [\n","    #             {'C': [1, 10,],'kernel' : ['rbf'],'degree' : [3]}\n","    # #          {'C': [1, 10, 100, 1000],'kernel' : ['linear','rbf','poly','sigmoid'],'degree' : [3,4,5,6]}\n","    #         ]\n","    #     svc = SVC()\n","    #     classificationModels.append(('Support Vector Classifier',svc,params_SVC))\n","    for name,model,params in classificationModels :\n","        print(\"------------------Running model -- {}  -------------------\".format(name))\n","        for i in params:\n","          for j in i.keys():\n","            keysOfParam.add(j)\n","        grid = GridSearchCV(model, params,verbose=1, scoring='accuracy', cv=3)\n","        grid.fit(X_train, Y_train.values.ravel())\n","        best_parameters = grid.best_estimator_.get_params()\n","        print(\"------------------Best Parameters for the model -- {}  -------------------\".format(name))\n","        for param_name in sorted(keysOfParam):\n","            if param_name in best_parameters.keys():\n","                print('%s: %r' % (param_name, best_parameters[param_name]))\n","        predictions = grid.predict(X_test)\n","        print('####Accuracy:', accuracy_score(Y_test, predictions))\n","        print('####Precision:', precision_score(Y_test, predictions))\n","        print('####Recall:', recall_score(Y_test, predictions))\n","        print(\"------------------Model came to END -- {}  -------------------\".format(name))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":2697533,"status":"error","timestamp":1530976868592,"user":{"displayName":"Sateesh Yavarn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"115031507397726858001"},"user_tz":-330},"id":"cNKwyqhKnFTL","outputId":"08b9d4ce-d4b0-483c-89f0-26b207785525","colab":{"base_uri":"https://localhost:8080/","height":676}},"source":["evaluateClassificationModels(X_train,X_test,Y_train,Y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["------------------Running model -- RandomForest  -------------------\n","Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 42.5min finished\n"],"name":"stderr"},{"output_type":"stream","text":["------------------Best Parameters for the model -- RandomForest  -------------------\n","criterion: 'entropy'\n","max_features: 'sqrt'\n","n_estimators: 100\n","####Accuracy: 0.7241920165769706\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-bb01555aabc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateClassificationModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-023edd3e1576>\u001b[0m in \u001b[0;36mevaluateClassificationModels\u001b[0;34m(X_train, X_test, Y_train, Y_test)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'####Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'####Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'####Recall:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------Model came to END -- {}  -------------------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1259\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1262\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1040\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1041\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n","\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."]}]}]}